{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions working:\n",
    "-     loadDataset: load the dataset \n",
    "-     preprocessing: convert into lower cases + tokenization + lemmatization\n",
    "-     split: split dataset into 75% training and 25% testing.\n",
    "-     initialize_ideal_answer: define ideal_answer\n",
    "-     encode_y = coverting y lables(categorical) to numbers(0/1)\n",
    "-     word_overlap_score: find similarity by comparing Training examples with an ideal answer\n",
    "-     alignment: returns features, which includes scores for each training examples.\n",
    "-     get_params: define parameters for the model.\n",
    "-     set_params: set the parameters of the model.\n",
    "-     trian: train the model\n",
    "-     predict: performance on the testing dataset.\n",
    "-     score: finding accuracy\n",
    "-     save: save the model locally\n",
    "-     load: load the model from local\n",
    "-     predict_probabilities: find confidence scores.\n",
    "\n",
    "Note: Dimension of the dataset is 100x2 (Its a matrix). The alignment function is made such that it will return a list (2d array)(Its a list). This is useful as we can use the same function for extracting features of training examples, testing examples, and for a new sentence ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "# will remove in the development mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVMClassifier:\n",
    "    def __init__(self):\n",
    "        self.tag_map = defaultdict(lambda : wn.NOUN)\n",
    "        self.tag_map['J'] = wn.ADJ\n",
    "        self.tag_map['V'] = wn.VERB\n",
    "        self.tag_map['R'] = wn.ADV\n",
    "        self.ideal_answer = None\n",
    "        self.model = None\n",
    "        self.score_dictionary = defaultdict(int)\n",
    "        \n",
    "    def loadDataset(self, file):\n",
    "        dataset = pd.read_csv(file, encoding=\"latin-1\")\n",
    "        return dataset\n",
    "    \n",
    "    def preprocessing(self, data):\n",
    "        preProcessedDataset = []\n",
    "        data = [entry.lower() for entry in data]\n",
    "        data = [word_tokenize(entry) for entry in data]\n",
    "        for index,entry in enumerate(data):\n",
    "            Final_words = []\n",
    "            word_Lemmatized = WordNetLemmatizer()\n",
    "            for word, tag in pos_tag(entry):\n",
    "                if word not in stopwords.words('english') and word.isalpha():\n",
    "                    word_Final = word_Lemmatized.lemmatize(word,self.tag_map[tag[0]])\n",
    "                    Final_words.append(word_Final)\n",
    "            preProcessedDataset.append(Final_words)\n",
    "        return preProcessedDataset\n",
    "    \n",
    "    def split(self, preProcessedDataset,Corpus):\n",
    "        Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(preProcessedDataset,Corpus['label'],test_size=0.25)\n",
    "        return Train_X, Test_X, Train_Y, Test_Y\n",
    "    \n",
    "    def initialize_ideal_answer(self, X):\n",
    "        self.ideal_answer = X[0]\n",
    "        print(\"ideal answer is = \", self.ideal_answer)\n",
    "\n",
    "    def encode_y(self, Train_Y, Test_Y):\n",
    "        Encoder = LabelEncoder()\n",
    "        Train_Y = Encoder.fit_transform(Train_Y)\n",
    "        Test_Y = Encoder.fit_transform(Test_Y)\n",
    "        return Train_Y, Test_Y\n",
    "    \n",
    "    def word_overlap_score(self, Train_X, ideal_answer):\n",
    "        features = []\n",
    "        for example in Train_X:\n",
    "            intersection = set(ideal_answer).intersection(set(example)) \n",
    "            score = len(intersection)/len(set(ideal_answer))\n",
    "            features.append(score)\n",
    "        return features\n",
    "        \n",
    "    #function for extracting features\n",
    "    def alignment(self, Train_X, ideal_answer):\n",
    "        if ideal_answer is None:\n",
    "            ideal_answer = self.ideal_answer\n",
    "        features = self.word_overlap_score(Train_X, ideal_answer)\n",
    "        return (np.array(features)).reshape(-1,1)\n",
    "    \n",
    "    def get_params(self):\n",
    "        C=1.0\n",
    "        kernel='linear'\n",
    "        degree=3\n",
    "        gamma='auto'\n",
    "        probability=True\n",
    "        return C,kernel, degree, gamma, probability\n",
    "    \n",
    "    def set_params(self, **params):\n",
    "        self.model = svm.SVC(C = params['C'], kernel = params['kernel'], degree = params['degree'], gamma = params['gamma'], probability = params['probability'] )\n",
    "    \n",
    "    def train(self, trainFeatures, Train_Y):\n",
    "        self.model.fit(trainFeatures, Train_Y)\n",
    "        print(\"Triaining complete\")\n",
    "        \n",
    "    def predict(self, testFeatures):\n",
    "        return self.model.predict(testFeatures)\n",
    "    \n",
    "    def score(self, model_predictions, Test_Y):\n",
    "        return accuracy_score(model_predictions, Test_Y)*100\n",
    "    \n",
    "    def save(self, filename):\n",
    "        pickle.dump(self.model, open(filename, 'wb'))\n",
    "        print(\"Model saved successfully!\")\n",
    "        \n",
    "    def load(self, filename):\n",
    "        model = pickle.load(open(filename, 'rb'))\n",
    "        return model\n",
    "\n",
    "    def confidence_score(self, sentence, expectation_number):\n",
    "        if expectation_number == None:\n",
    "            pass\n",
    "        else:\n",
    "            model = self.load(\"model\" + str(expectation_number))\n",
    "            self.score_dictionary[expectation_number] = [model.predict(sentence)[0], model.decision_function(sentence)[0]]\n",
    "            return self.score_dictionary\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text        label\n",
      "0   Stuning even for the non-gamer: This sound tr...  __label__1 \n",
      "1   The best soundtrack ever to anything.: I'm re...  __label__2 \n",
      "2   Amazing!: This soundtrack is my favorite musi...  __label__2 \n",
      "3   Excellent Soundtrack: I truly like this sound...  __label__1 \n",
      "4   Remember, Pull Your Jaw Off The Floor After H...  __label__2 \n",
      "5   an absolute masterpiece: I am quite sure any ...  __label__1 \n",
      "6   Buyer beware: This is a self-published book, ...  __label__1 \n",
      "7   Glorious story: I loved Whisper of the wicked...  __label__1 \n",
      "8   A FIVE STAR BOOK: I just finished reading Whi...  __label__2 \n",
      "9   Whispers of the Wicked Saints: This was a eas...  __label__1 \n"
     ]
    }
   ],
   "source": [
    "expectation1 = SVMClassifier()\n",
    "Corpus = expectation1.loadDataset('exp1_dataset.csv')\n",
    "print(Corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "preProcessedDataset = expectation1.preprocessing(Corpus['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_X, Test_X, Train_Y, Test_Y = expectation1.split(preProcessedDataset, Corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ideal answer is =  ['buyer', 'beware', 'book', 'want', 'know', 'read', 'paragraph', 'star', 'review', 'must', 'write', 'haddon', 'family', 'friend', 'perhaps', 'ca', 'imagine', 'anyone', 'read', 'whole', 'thing', 'spend', 'evening', 'book', 'friend', 'hysteric', 'read', 'bit', 'piece', 'one', 'another', 'definitely', 'bad', 'enough', 'enter', 'kind', 'bad', 'book', 'contest', 'ca', 'believe', 'amazon', 'even', 'sell', 'kind', 'thing', 'maybe', 'offer', 'grade', 'term', 'paper', 'kill', 'mockingbird', 'book', 'quite', 'sure', 'haddon', 'never', 'heard', 'anyway', 'unless', 'mood', 'send', 'book', 'someone', 'joke', 'far', 'far', 'away', 'one']\n"
     ]
    }
   ],
   "source": [
    "expectation1.initialize_ideal_answer(Train_X)\n",
    "Train_Y, Test_Y = expectation1.encode_y(Train_Y, Test_Y)\n",
    "features = expectation1.alignment(Train_X, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triaining complete\n",
      "[0 0 0 0 0 0 0]\n",
      "57.14285714285714\n"
     ]
    }
   ],
   "source": [
    "C,kernel, degree, gamma, probability = expectation1.get_params()\n",
    "model = expectation1.set_params(C=1.0, kernel='linear', degree=3, gamma='auto', probability=True)\n",
    "expectation1.train(features, Train_Y)\n",
    "train_pred = expectation1.predict(features)\n",
    "print(train_pred)\n",
    "print(expectation1.score(train_pred, Train_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0]\n",
      "Accuracy of the model:  66.66666666666666\n"
     ]
    }
   ],
   "source": [
    "testFeatures = expectation1.alignment(Test_X, None)\n",
    "model_predictions = expectation1.predict(testFeatures)\n",
    "print(model_predictions)\n",
    "accuracy = expectation1.score(model_predictions, Test_Y)\n",
    "print(\"Accuracy of the model: \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "expectation1.save('model1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = expectation1.load('model1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = ['unfortunately entertain least Awful beyond belief!: I feel I have to write to keep others from wasting their money. This book seems to have been written by a 7th grader with poor grammatical skills for her age! As another reviewer points out, there is a misspelling on the cover, and I believe there is at least one per chapter. For example, it was mentioned twice that she had a \"lean\" on her house. I was so distracted by the poor writing and weak plot, that I decided to read with a pencil in hand to mark all of the horrible grammar and spelling. Please dont waste your money. I too, believe that the good reviews must have been written by the authors relatives. I will not put much faith in the reviews from now on!']\n",
    "sent_proc = expectation1.preprocessing(sentence)\n",
    "sent_features = expectation1.alignment(sent_proc, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.]\n"
     ]
    }
   ],
   "source": [
    "confidence_score = model1.decision_function(sent_features)\n",
    "print(confidence_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Second expectation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text        label\n",
      "0   The Worst!: A complete waste of time. Typogra...  __label__1 \n",
      "1   Great book: This was a great book,I just coul...  __label__2 \n",
      "2   Great Read: I thought this book was brilliant...  __label__2 \n",
      "3   Oh please: I guess you have to be a romance n...  __label__1 \n",
      "4   Awful beyond belief!: I feel I have to write ...  __label__1 \n",
      "5   Don't try to fool us with fake reviews.: It's...  __label__1 \n",
      "6   A romantic zen baseball comedy: When you hear...  __label__2 \n",
      "7   Fashionable Compression Stockings!: After I h...  __label__2 \n",
      "8   Jobst UltraSheer Thigh High: Excellent produc...  __label__2 \n",
      "9   sizes recomended in the size chart are not re...  __label__1 \n"
     ]
    }
   ],
   "source": [
    "expectation2 = SVMClassifier()\n",
    "Corpus = expectation2.loadDataset('exp2_dataset.csv')\n",
    "print(Corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "preProcessedDataset = expectation2.preprocessing(Corpus['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_X, Test_X, Train_Y, Test_Y = expectation2.split(preProcessedDataset, Corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ideal answer is =  ['great', 'read', 'think', 'book', 'brilliant', 'yet', 'realistic', 'show', 'error', 'human', 'love', 'fact', 'writer', 'show', 'loving', 'side', 'god', 'revengeful', 'side', 'love', 'twist', 'turn', 'could', 'put', 'also', 'love', 'glass', 'castle']\n"
     ]
    }
   ],
   "source": [
    "expectation2.initialize_ideal_answer(Train_X)\n",
    "Train_Y, Test_Y = expectation2.encode_y(Train_Y, Test_Y)\n",
    "features = expectation2.alignment(Train_X, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triaining complete\n",
      "[1 0 0 0 0 0 0]\n",
      "71.42857142857143\n"
     ]
    }
   ],
   "source": [
    "C,kernel, degree, gamma, probability = expectation2.get_params()\n",
    "model = expectation2.set_params(C=1.0, kernel='linear', degree=3, gamma='auto', probability=True)\n",
    "expectation2.train(features, Train_Y)\n",
    "train_pred = expectation2.predict(features)\n",
    "print(train_pred)\n",
    "print(expectation2.score(train_pred, Train_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0]\n",
      "Accuracy of the model:  33.33333333333333\n"
     ]
    }
   ],
   "source": [
    "testFeatures = expectation2.alignment(Test_X, None)\n",
    "model_predictions = expectation2.predict(testFeatures)\n",
    "print(model_predictions)\n",
    "accuracy = expectation2.score(model_predictions, Test_Y)\n",
    "print(\"Accuracy of the model: \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "expectation2.save('model2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = expectation2.load('model2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = ['unfortunately entertain least Awful beyond belief!: I feel I have to write to keep others from wasting their money. This book seems to have been written by a 7th grader with poor grammatical skills for her age! As another reviewer points out, there is a misspelling on the cover, and I believe there is at least one per chapter. For example, it was mentioned twice that she had a \"lean\" on her house. I was so distracted by the poor writing and weak plot, that I decided to read with a pencil in hand to mark all of the horrible grammar and spelling. Please dont waste your money. I too, believe that the good reviews must have been written by the authors relatives. I will not put much faith in the reviews from now on!']\n",
    "sent_proc = expectation2.preprocessing(sentence)\n",
    "sent_features = expectation2.alignment(sent_proc, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.125]]\n"
     ]
    }
   ],
   "source": [
    "print(sent_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "expectation_number = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {2: [0, -0.9062500010477379]})\n"
     ]
    }
   ],
   "source": [
    "ans = expectation1.confidence_score(sent_features, 2)\n",
    "print(ans)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
